/*
github.com/tcrain/cons - Experimental project for testing and scaling consensus algorithms.
Copyright (C) 2020 The project authors - tcrain

This program is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License
along with this program.  If not, see <https://www.gnu.org/licenses/>.

*/

package network

import (
	"fmt"
	"github.com/tcrain/cons/consensus/auth/sig/bls"
	"github.com/tcrain/cons/consensus/auth/sig/ed"
	"math/rand"
	"sync"

	"github.com/tcrain/cons/config"
	"github.com/tcrain/cons/consensus/auth/sig"
	"github.com/tcrain/cons/consensus/logging"
	"github.com/tcrain/cons/consensus/types"
)

// ParticipantRegister is used during tests to track the nodes that will participate to initialize an experiment.
// Each node will register itself with the ParticipantRegister, then request the list of other participants.
// Once enough nodes have registered, the ParticipantRegister will let all nodes know the other participants
// and who they will connect to based on the NetworkPropagationSetup.
// It is not meant to be secure, anyone can register.
// The operations are concurrent safe.
type ParticipantRegister struct {
	cond          *sync.Cond
	mutex         sync.Mutex
	connType      NetworkPropagationSetup            // The network setup for the test.
	count         int                                // The maximum number of participants.
	connInfoMap   map[sig.PubKeyStr]*ParticipantInfo // Map from pub key to participant info.
	connInfoList  []*ParticipantInfo                 // List of registered participants.
	numRegistered int                                // Number of participants registered so far.
	p2pConMap     []map[int][]int                    // Used when NetworkPropagationType == P2p, it maps a node to the other nodes it will connect to
	dssShared     ed.DSSSharedMarshaled              // For when using EDCOIN threshold signatures, note note safe since centralized
	blsShared     map[int]*bls.BlsSharedMarshal      // For when using BLS threshold signatures, note note safe since centralized
	thrshCond     *sync.Cond
	thrshMutex    sync.Mutex
}

// NewParReg generates a new participant register for the given network propagation setup and count expected participants
func NewParReg(connType NetworkPropagationSetup, count int) (pr *ParticipantRegister) {
	pr = &ParticipantRegister{}
	pr.connType = connType
	pr.count = count
	pr.cond = sync.NewCond(&pr.mutex)
	pr.thrshCond = sync.NewCond(&pr.thrshMutex)
	pr.connInfoList = make([]*ParticipantInfo, count)
	pr.connInfoMap = make(map[sig.PubKeyStr]*ParticipantInfo, count)
	pr.blsShared = make(map[int]*bls.BlsSharedMarshal)
	return
}

// GenBlsShared generates a shared bls threshold key object for the given threshold.
// This is not safe since it is centralized.
func (pr *ParticipantRegister) GenBlsShared(idx int, numThresh int) error {
	pr.mutex.Lock()
	defer pr.mutex.Unlock()

	blss, err := bls.NewBlsShared(pr.count, numThresh).PartialMarshal()
	if err != nil {
		return err
	}
	pr.blsShared[idx] = &blss

	return nil
}

// GetBlsShared returns the index of the request to GetBlsShared and the blsShared object
// This is not safe since it returns all private keys.
func (pr *ParticipantRegister) GetBlsShared(idx int) (index int, blsShared *bls.BlsSharedMarshal) {
	pr.mutex.Lock()
	defer pr.mutex.Unlock()

	blsShared = pr.blsShared[idx]

	return
}

// GenDSSShared generates a shared threshold key object for the given threshold.
// This is not safe since it is centralized.
func (pr *ParticipantRegister) GenDSSShared(numNonNumbers, numThresh int) error {
	pr.mutex.Lock()
	defer pr.mutex.Unlock()

	dsss, err := ed.NewDSSShared(pr.count, numNonNumbers, numThresh).PartialMarshal()
	if err != nil {
		return err
	}
	pr.dssShared = dsss
	return nil
}

// GetDSSShared returns the DSSSharedMarshaled object generated by GenDSSShared.
func (pr *ParticipantRegister) GetDSSShared() ed.DSSSharedMarshaled {
	pr.mutex.Lock()
	defer pr.mutex.Unlock()

	return pr.dssShared
}

// RegisterParticipant registers a participant for consensus. It can be called multiple times
// for the same public key, this will not count as a new participant, but will update the object
// (in case the connections have changed).
func (pr *ParticipantRegister) RegisterParticipant(parInfo *ParticipantInfo) error {
	pr.mutex.Lock()
	defer pr.mutex.Unlock()
	// keyBytes, err := parInfo.Pub.GetPubString()
	// if err != nil {
	//	return err
	// }
	keyBytes := parInfo.Pub
	if old := pr.connInfoMap[keyBytes]; old != nil {
		logging.Infof("Re-register participant: %v, previous was %v", parInfo, old)
		if parInfo.RegisterCount != old.RegisterCount {
			return fmt.Errorf("should not change index on re-register, old %v, new %v",
				old.RegisterCount, parInfo.RegisterCount)
		}
		pr.connInfoList[old.RegisterCount] = parInfo
	} else {
		pr.numRegistered++
		if old := pr.connInfoList[parInfo.RegisterCount]; old != nil {
			if old.Pub != parInfo.Pub {
				return fmt.Errorf("registered two different pubs at index %v", old.RegisterCount)
			}
		}
		pr.connInfoList[parInfo.RegisterCount] = parInfo
	}
	pr.connInfoMap[keyBytes] = parInfo

	if len(pr.connInfoMap) >= pr.count {
		if pr.connType.NPT == types.P2p {
			pr.genP2p()
		}
		pr.cond.Broadcast()
	}
	return nil
}

// GetParticipants takes an existing partcipant as input, then returns the set of participants
// it should connect to based on the network setup. The function block until enough participants
// have registered.
func (pr *ParticipantRegister) GetParticipants(pub sig.PubKeyStr) ([][]*ParticipantInfo, error) {
	pr.mutex.Lock()
	defer pr.mutex.Unlock()

	for len(pr.connInfoMap) < pr.count {
		pr.cond.Wait()
	}
	switch pr.connType.NPT {
	case types.AllToAll, types.Random:
		// pr.mutex.Unlock()
		return pr.getAlltoAll(pub)
	case types.P2p:
		// pr.mutex.Unlock()
		return pr.getP2p(pub)
	case types.RequestForwarder: // The node computes its connection using a local rand, so we return nil here
		// return pr.getAlltoAll(pub)
		return nil, nil
	default:
		panic("Used unknown conn type")
	}
}

// GetAllParticipants returns the list of all registered participants. It will
// block until enough participants have registered. Note that the list is not
// expected to be sorted, the nodes have to sort the public keys on their own.
func (pr *ParticipantRegister) GetAllParticipants() ([]*ParticipantInfo, error) {
	pr.mutex.Lock()

	for len(pr.connInfoMap) < pr.count {
		pr.cond.Wait()
	}
	ret := make([]*ParticipantInfo, len(pr.connInfoList))
	copy(ret, pr.connInfoList)
	pr.mutex.Unlock()

	return ret, nil
}

func (pr *ParticipantRegister) getAlltoAll(pstr sig.PubKeyStr) ([][]*ParticipantInfo, error) {
	// pstr, err := pub.GetPubString()
	// if err != nil {
	//	return nil, err
	// }

	if _, ok := pr.connInfoMap[pstr]; !ok {
		return nil, types.ErrPubNotFound
	}
	var ret []*ParticipantInfo
	for p, c := range pr.connInfoMap {
		if p != pstr {
			ret = append(ret, c)
		}
	}
	return [][]*ParticipantInfo{ret}, nil
}

// var ErrNotSupported = fmt.Errorf("to implement")

func (pr *ParticipantRegister) getP2p(pstr sig.PubKeyStr) ([][]*ParticipantInfo, error) {
	// pstr, err := pub.GetPubString()
	// if err != nil {
	//	return nil, err
	// }

	parInfo, ok := pr.connInfoMap[pstr]
	if !ok {
		return nil, types.ErrPubNotFound
	}

	ret := make([][]*ParticipantInfo, pr.connType.AdditionalP2PNetworks+1)
	for pi := range ret {
		idxs := pr.p2pConMap[pi][parInfo.RegisterCount]
		for _, i := range idxs {
			ret[pi] = append(ret[pi], pr.connInfoList[i])
		}
	}
	return ret, nil
}

func (pr *ParticipantRegister) genP2p() {
	if pr.p2pConMap != nil {
		return
	}
	pr.p2pConMap = make([]map[int][]int, pr.connType.AdditionalP2PNetworks+1)

out:
	for pi := range pr.p2pConMap {
		for r := 0; r < config.P2pGraphGenerateRetries; r++ {
			pr.p2pConMap[pi] = make(map[int][]int)
			for i := range pr.connInfoList {
				var ret []int
				idxs := rand.Perm(len(pr.connInfoList))
				j := 0
				for len(ret) < pr.connType.FanOut {
					if idxs[j] != i {
						ret = append(ret, idxs[j])
					}
					j++
				}
				//ret = append(ret, pr.connInfoMap[pstr])
				pr.p2pConMap[pi][i] = ret
			}
			if checkConnectivity(pr.p2pConMap[pi]) {
				logging.Info("The connection map:", pr.p2pConMap[pi])
				continue out
			}
		}
		panic("Unalbe to generate connected graph")
	}
}

func checkConnectivity(cons map[int][]int) bool {
	numNodes := len(cons)
	for i := range cons {
		reached := make([]bool, numNodes)
		recCheckConnectivity(i, cons, reached)
		if !allTrue(reached) {
			return false
		}
	}
	return true
}

func recCheckConnectivity(index int, items map[int][]int, soFar []bool) {
	if soFar[index] {
		return
	}
	soFar[index] = true
	for _, nxt := range items[index] {
		recCheckConnectivity(nxt, items, soFar)
	}

}

func allTrue(check []bool) bool {
	for _, nxt := range check {
		if !nxt {
			return false
		}
	}
	return true
}
